{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Load complete...\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "dtypes = {'id':'uint32', 'item_nbr':'int32', 'store_nbr':'int8', 'unit_sales':'float32', 'onpromotion':'bool' }\n",
    "\n",
    "# load or create your dataset\n",
    "print('Loading data...')\n",
    "df_train = pd.read_csv(\"data/train.csv\", dtype=dtypes, parse_dates=[\"date\"], low_memory=True, usecols=[1, 2, 3, 4, 5], skiprows=range(1, 106458909) )\n",
    "df_test = pd.read_csv(\"data/test.csv\", usecols=[0, 1, 2, 3, 4], dtype={'onpromotion': bool}, parse_dates=[\"date\"] ).set_index(['store_nbr', 'item_nbr', 'date'])\n",
    "items = pd.read_csv(\"data/items.csv\").set_index(\"item_nbr\")\n",
    "print('Load complete...')\n",
    "\n",
    "df_2017 = df_train\n",
    "del df_train\n",
    "\n",
    "# Apilar en columnas las filas de Date para Train enfocandose en las Promociones\n",
    "promo_2017_train = df_2017.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "# Asignar el nombre de las fechas en las columnas de Train\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "\n",
    "# Apilar en columnas las filas de Date para Test enfocandose en las Promociones\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "\n",
    "# Asignar el nombre de las fechas en las columnas de Test\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "\n",
    "# Ajustamos los indices de Test en base a los de train\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "# Apilar en columnas las filas de Date para Train enfocandose en las Unidades\n",
    "df_2017 = df_2017.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "# Asignar el nombre de las fechas en las columnas de Train\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "#Ventas diarias (Columnas) de Unidades para cada Tienda y cada Item de tienda (Filas)\n",
    "df_2017\n",
    "\n",
    "# Reindexo items en base a los Items disponibles en Train\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "items.head()\n",
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        # Calcula el promedio de los 3 días anteriores a la fecha deseada t2017\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        #\"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        #\"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        #Promedio de Ventas en base a Dia de la Semana\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        #X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        # Unidades Vendidas de Items por tienda para los 16 días posteriores a la fecha deseada t2017\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "\n",
    "# Elige una ventana temporal de 6\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    print(\"Calculando promedios deseados para la fecha: \",t2017 + delta)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        # Calcula promedios deseados para fechas cada 7 días (7,14,21,...,42)\n",
    "        t2017 + delta\n",
    "    )\n",
    "    # Unir a lista los valores de X\n",
    "    X_l.append(X_tmp)\n",
    "    # Unir a lista los valores de y\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "# Concatenamos todos los valores de X\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "# Concatenamos todos los valores de y\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "\n",
    "# Calcula un X y y en base a una fecha deseada (Aún no comprendo porqué)\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "# Calculamos el X_test en base al último día + 1 disponible de registros\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 50\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "# Son 16 vueltas porque se van a predecir 16 días! empezando desde 2017-08-16 hasta 2017-08-31\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        # Concatenamos 6 veces items porque se eligió una ventana temporal de 6 y se concatenaron 6 X_train anteriormente.\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=20, verbose_eval=100\n",
    "    )\n",
    "    #Imprime los promedios deseados de \"Prepare_dataset\"\n",
    "    #print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        #zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        #key=lambda x: x[1], reverse=True\n",
    "    #)))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    #Guarda la predicción de cada día\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n",
    "    print(\"Val_Pred: \",val_pred)\n",
    "    print(\"Test_pred: \",test_pred)\n",
    "\n",
    "#Evalua el rendimiento en un fragmento comparando las predicciones para uno de los 16 días\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "# Une las predicciones con el test (basandose en tienda, item y fecha) y los que no estén entonces lo llena con 0\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
